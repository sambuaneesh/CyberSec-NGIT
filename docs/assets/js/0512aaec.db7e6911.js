"use strict";(self.webpackChunkdocumentation=self.webpackChunkdocumentation||[]).push([[4399],{5147:e=>{e.exports=JSON.parse('{"blogPosts":[{"id":"neural-networks","metadata":{"permalink":"/CyberSec-NGIT/blog/neural-networks","editUrl":"https://github.com/stealthspectre/CyberSec-NGIT/blog/neural-networks.md","source":"@site/blog/neural-networks.md","title":"Neural Networks \ud83e\udde0","description":"So? What\'s the story of this Neural thing?","date":"2023-03-30T06:48:46.809Z","formattedDate":"March 30, 2023","tags":[{"label":"ml","permalink":"/CyberSec-NGIT/blog/tags/ml"},{"label":"dl","permalink":"/CyberSec-NGIT/blog/tags/dl"}],"readingTime":1.695,"hasTruncateMarker":false,"authors":[{"name":"Aneesh Sambu","title":"stealthspectre","url":"https://github.com/stealthspectre","imageURL":"https://github.com/stealthspectre.png","key":"aneesh"}],"frontMatter":{"slug":"neural-networks","title":"Neural Networks \ud83e\udde0","authors":"aneesh","tags":["ml","dl"]},"nextItem":{"title":"What is Gaussian?","permalink":"/CyberSec-NGIT/blog/gaussian"}},"content":"## So? What\'s the story of this Neural thing?\\r\\n\\r\\n- These are artificial mathematical models which are inspired from our biological neural networks\\r\\n- so basically it has three layers\\r\\n\\r\\n  1.  **Input Layer**\\r\\n  2.  **Output Layer**\\r\\n  3.  **Hidden Layers**\\r\\n\\r\\n- | ![](https://i.imgur.com/dFkw7xx.png) | ![](https://i.imgur.com/AsaMDnE.png) | ![](https://i.imgur.com/UEzwltc.png) |\\r\\n  | ------------------------------------ | ------------------------------------ | ------------------------------------ |\\r\\n\\r\\n- all between cells are called as **neurons**\\r\\n- hidden layers do the most of the computations\\r\\n  ![](https://i.imgur.com/75KkWUF.png)\\r\\n- basically all these layers are connected with which we call as **channels**\\r\\n- each channel has its own numerical **weight**\\r\\n- the inputs are multiplied with the corresponding weight of the channel and then each neuron in hidden layer has a value which is known as a **bias**\\r\\n- this bias is added to the multiplied value and is passed through a threshold function known as the **activation function**\\r\\n- the result coming from the activation function determines whether the neuron is activated or not\\r\\n- and then activated neurons participate in the further channels and they are propagated untill a final prediction is made\\r\\n- this propagation is known as the **forward propagation**\\r\\n- now at first we may not get the correct prediction as shown in the above picture, so now the error magnitude is calculated and based on that flow in reverse direction happen which is known as **backward propagation**\\r\\n\\r\\n  ![](https://i.imgur.com/03SmHdJ.png)\\r\\n\\r\\n- as this backward propagation takes place, the weights adjust themselves in such a way that they can predict correctly for a given data\\r\\n- in this manner huge labeled data is trained so that neural network can get proper weights and it can predict properly\\r\\n- it is a very time consuming and high computational process\\r\\n\\r\\n---\\r\\n\\r\\n## What are the real time examples?\\r\\n\\r\\n- Facial Recognition\\r\\n- Forecasting (Weather forecast etc)\\r\\n- Music Composition\\r\\n\\r\\n**Note**\\r\\n\\r\\n- Anything in real life, which follows a pattern kind of resemblance, a neural network can be applied and trained\\r\\n- Neural Networks come under deep learning which is a subset of machine learning\\r\\n\\r\\n---"},{"id":"gaussian","metadata":{"permalink":"/CyberSec-NGIT/blog/gaussian","editUrl":"https://github.com/stealthspectre/CyberSec-NGIT/blog/gaussian.md","source":"@site/blog/gaussian.md","title":"What is Gaussian?","description":"What\'s a Gaussian Distribution?","date":"2023-03-29T11:34:14.216Z","formattedDate":"March 29, 2023","tags":[{"label":"algo","permalink":"/CyberSec-NGIT/blog/tags/algo"},{"label":"gaussian","permalink":"/CyberSec-NGIT/blog/tags/gaussian"},{"label":"gaussian naive bayes","permalink":"/CyberSec-NGIT/blog/tags/gaussian-naive-bayes"}],"readingTime":2.125,"hasTruncateMarker":false,"authors":[{"name":"Aneesh Sambu","title":"stealthspectre","url":"https://github.com/stealthspectre","imageURL":"https://github.com/stealthspectre.png","key":"aneesh"}],"frontMatter":{"slug":"gaussian","title":"What is Gaussian?","authors":"aneesh","tags":["algo","gaussian","gaussian naive bayes"]},"prevItem":{"title":"Neural Networks \ud83e\udde0","permalink":"/CyberSec-NGIT/blog/neural-networks"},"nextItem":{"title":"What are Regressive tasks?","permalink":"/CyberSec-NGIT/blog/regression"}},"content":"## What\'s a Gaussian Distribution?\\r\\n\\r\\n![](https://th.bing.com/th/id/OIP.QSPgbSo7zQz6-jZQUTEwGQHaDh?pid=ImgDet&rs=1)\\r\\n\\r\\nThe Gaussian distribution is often used to model real-world phenomena that are naturally distributed around a central value, such as the heights of people in a population, the weights of objects, or the errors in a measurement. It is also used in many machine learning algorithms, such as linear regression, logistic regression, and Gaussian mixture models.\\r\\nThe Gaussian distribution has several important properties, such as the 68-95-99.7 rule, which states that approximately 68% of the data falls within one standard deviation of the mean, 95% falls within two standard deviations, and 99.7% falls within three standard deviations. This makes it a useful tool for analyzing and modeling data in many different fields.\\r\\n\\r\\n---\\r\\n\\r\\n## What is a Gaussian Naive Bayes Classifier?\\r\\n\\r\\n### Simple Definition\\r\\n\\r\\nGaussian naive Bayes classifiers are a type of probabilistic classifier that assume that the features of a data point are independent and normally distributed, and use Bayes\' theorem to calculate the probability of each class given the features.\\r\\n\\r\\n### Lets dive Deeper\\r\\n\\r\\nGaussian [Naive Bayes](/docs/ML-Based%20Zero%20Day%20Detection/ml-algorithms#na%C3%AFve-bayes) (GNB) is a probabilistic classifier that is based on Bayes\' theorem and assumes that the features of a data point are independent and normally distributed. It is called \\"naive\\" because it makes a strong assumption of independence between the features, which may not always be true in practice. Despite this simplifying assumption, GNB can be surprisingly effective in many real-world applications.\\r\\n\\r\\nThe GNB classifier works by first estimating the mean and variance of each feature for each class in the training data. Then, given a new data point with features x, it calculates the probability of each class c using Bayes\' theorem:\\r\\n\\r\\n**P(c|x) = P(x|c) \\\\* P(c) / P(x)**\\r\\n\\r\\n- where P(c|x) is the probability of class c given the features x\\r\\n- P(x|c) is the probability of observing the features x given class c (which is modeled as a Gaussian distribution with mean and variance estimated from the training data)\\r\\n- P(c) is the prior probability of class c (which is estimated from the relative frequency of each class in the training data)\\r\\n- P(x) is the marginal probability of observing the features x (which can be calculated as the sum of P(x|c) \\\\_ P(c) over all classes).\\r\\n\\r\\nFinally, the GNB classifier predicts the class with the highest probability. In practice, GNB can be very fast and efficient, especially for high-dimensional data with many features. However, it may not perform well if the independence assumption is strongly violated or if the data is not well-modeled by a Gaussian distribution."},{"id":"regression","metadata":{"permalink":"/CyberSec-NGIT/blog/regression","editUrl":"https://github.com/stealthspectre/CyberSec-NGIT/blog/regression.md","source":"@site/blog/regression.md","title":"What are Regressive tasks?","description":"So what\'s this Regression?","date":"2023-03-29T10:54:53.139Z","formattedDate":"March 29, 2023","tags":[{"label":"regression","permalink":"/CyberSec-NGIT/blog/tags/regression"},{"label":"classification","permalink":"/CyberSec-NGIT/blog/tags/classification"},{"label":"ml","permalink":"/CyberSec-NGIT/blog/tags/ml"},{"label":"algo","permalink":"/CyberSec-NGIT/blog/tags/algo"}],"readingTime":2.3,"hasTruncateMarker":false,"authors":[{"name":"Aneesh Sambu","title":"stealthspectre","url":"https://github.com/stealthspectre","imageURL":"https://github.com/stealthspectre.png","key":"aneesh"}],"frontMatter":{"slug":"regression","title":"What are Regressive tasks?","authors":"aneesh","tags":["regression","classification","ml","algo"]},"prevItem":{"title":"What is Gaussian?","permalink":"/CyberSec-NGIT/blog/gaussian"},"nextItem":{"title":"Diving into KNN","permalink":"/CyberSec-NGIT/blog/knn"}},"content":"## So what\'s this Regression?\\r\\n\\r\\nIn machine learning, a regression task is a type of supervised learning problem where the goal is to predict a continuous numerical value, such as a price, a temperature, or a stock price. The objective of a regression model is to learn a function that maps input features to a continuous output value.\\r\\n\\r\\nRegression tasks are different from classification tasks, where the goal is to predict a categorical label, such as whether an email is spam or not. In a regression task, the output variable is a continuous value, whereas in a classification task, the output variable is a discrete value.\\r\\n\\r\\nRegression models can be used for a wide range of applications, such as predicting housing prices based on features like location, square footage, and number of bedrooms, or predicting the temperature based on weather conditions like humidity, wind speed, and cloud cover.\\r\\n\\r\\nThere are many different types of regression models, including linear regression, polynomial regression, and decision tree regression. The choice of model depends on the specific problem and the characteristics of the data. The performance of a regression model is typically evaluated using metrics like mean squared error (MSE) or root mean squared error (RMSE), which measure the difference between the predicted values and the actual values.\\r\\n\\r\\n---\\r\\n\\r\\n## What is the main difference between classification and regression?\\r\\n\\r\\nThe main difference between regression and classification tasks in machine learning is the type of output that the model is trying to predict.\\r\\n\\r\\nIn a regression task, the goal is to predict a continuous numerical value, such as a price, a temperature, or a stock price. The objective of a regression model is to learn a function that maps input features to a continuous output value.\\r\\n\\r\\nIn a classification task, on the other hand, the goal is to predict a categorical label, such as whether an email is spam or not, or whether a patient has a certain disease or not. The output variable is a discrete value, and the model is trained to classify input data into one of several predefined categories.\\r\\n\\r\\nAnother key difference between regression and classification tasks is the type of algorithms that are used. Regression models typically use algorithms like linear regression, polynomial regression, or decision tree regression, while classification models use algorithms like logistic regression, decision trees, or support vector machines.\\r\\n\\r\\nThe evaluation metrics used for regression and classification tasks are also different. For regression tasks, metrics like mean squared error (MSE) or root mean squared error (RMSE) are commonly used to measure the difference between the predicted values and the actual values. For classification tasks, metrics like accuracy, precision, recall, and F1 score are used to measure the performance of the model in correctly classifying the input data."},{"id":"knn","metadata":{"permalink":"/CyberSec-NGIT/blog/knn","editUrl":"https://github.com/stealthspectre/CyberSec-NGIT/blog/knn.md","source":"@site/blog/knn.md","title":"Diving into KNN","description":"Plain Definition","date":"2023-03-29T10:45:19.848Z","formattedDate":"March 29, 2023","tags":[{"label":"ml","permalink":"/CyberSec-NGIT/blog/tags/ml"},{"label":"knn","permalink":"/CyberSec-NGIT/blog/tags/knn"},{"label":"weighted knn","permalink":"/CyberSec-NGIT/blog/tags/weighted-knn"},{"label":"algo","permalink":"/CyberSec-NGIT/blog/tags/algo"}],"readingTime":4.175,"hasTruncateMarker":false,"authors":[{"name":"Aneesh Sambu","title":"stealthspectre","url":"https://github.com/stealthspectre","imageURL":"https://github.com/stealthspectre.png","key":"aneesh"}],"frontMatter":{"slug":"knn","title":"Diving into KNN","authors":"aneesh","tags":["ml","knn","weighted knn","algo"]},"prevItem":{"title":"What are Regressive tasks?","permalink":"/CyberSec-NGIT/blog/regression"},"nextItem":{"title":"What is a Parametric Algorithm?","permalink":"/CyberSec-NGIT/blog/parametric"}},"content":"## Plain Definition\\r\\n\\r\\nKNN (K-Nearest Neighbors) is a machine learning algorithm used for classification and [regression tasks](/blog/regression). It is a [non-parametric algorithm](/blog/non-parametric), which means that it does not make any assumptions about the underlying distribution of the data.\\r\\n\\r\\nIn the KNN algorithm, the input data is represented as points in a high-dimensional space, and the algorithm classifies new data points based on their proximity to the existing data points. Specifically, the algorithm calculates the distance between the new data point and each of the existing data points, and then assigns the new data point to the class that is most common among its K nearest neighbors.\\r\\n\\r\\nThe value of K is a hyperparameter that can be tuned to optimize the performance of the algorithm. A larger value of K will result in a smoother decision boundary, but may also lead to misclassification of data points that are close to the boundary between two classes.\\r\\n\\r\\nKNN is a simple and effective algorithm that can be used for a wide range of classification and [regression tasks](/blog/regression). However, it can be computationally expensive for large datasets, and may not perform well in high-dimensional spaces.\\r\\n\\r\\n---\\r\\n\\r\\n## Real time example\\r\\n\\r\\nImagine you are a penguin living in Antarctica, and you want to find a new place to build your igloo. You have heard that some areas are better than others, but you\'re not sure which ones. So, you decide to ask your penguin friends for advice.\\r\\n\\r\\nYou ask your friends to rate different areas on a scale of 1 to 10, based on how good they are for building an igloo. You also ask them to tell you the distance of each area from your current location.\\r\\n\\r\\nNow, you have a dataset of ratings and distances for different areas. You want to use this data to find the best place to build your igloo.\\r\\n\\r\\nThis is where KNN comes in. It can help you find the best place to build your igloo based on the ratings and distances provided by your friends.\\r\\n\\r\\nHere\'s how it works:\\r\\n\\r\\n1. You choose a value for K. This is the number of neighbors you want to consider when making a decision. Let\'s say you choose K=3.\\r\\n2. You calculate the distance between each area and your current location.\\r\\n3. You find the 3 areas that are closest to your current location.\\r\\n4. You look at the ratings for these 3 areas, and take the average. This gives you a predicted rating for each of the 3 areas.\\r\\n5. You choose the area with the highest predicted rating as the best place to build your igloo.\\r\\n\\r\\nSo, in this example, KNN helped you find the best place to build your igloo based on the ratings and distances provided by your friends.\\r\\n\\r\\nOf course, in real life, KNN can be used for many other things besides finding the best place to build an igloo. For example, it can be used to predict the price of a house based on its features, or to classify images based on their content.\\r\\n\\r\\nBut hopefully this fun example helps you understand the basic idea behind KNN!\\r\\n\\r\\n---\\r\\n\\r\\n## Now what is this weighted KNN?\\r\\n\\r\\nWeighted KNN is a variation of the KNN algorithm where the contribution of each of the K nearest neighbors is weighted according to their distance from the query point. In other words, the closer a neighbor is to the query point, the more weight it is given in the final prediction.\\r\\n\\r\\nIn the standard KNN algorithm, all K neighbors are given equal weight in the final prediction. However, this may not always be the best approach, as some neighbors may be more relevant than others depending on their distance from the query point.\\r\\n\\r\\nFor example, let\'s say you are trying to predict the price of a house based on its features, such as the number of bedrooms, bathrooms, and square footage. In a standard KNN algorithm, the K nearest neighbors are chosen based solely on their feature values, without considering their distance from the query point. However, it\'s possible that some of these neighbors are located far away from the query point, and therefore may not be as relevant to the prediction.\\r\\n\\r\\nIn a weighted KNN algorithm, the contribution of each neighbor is weighted based on its distance from the query point. This means that neighbors that are closer to the query point are given more weight in the final prediction, while neighbors that are farther away are given less weight.\\r\\n\\r\\nUsing the same example of predicting house prices, this means that the K nearest neighbors are chosen based on both their feature values and their distance from the query point. The closer a neighbor is to the query point, the more weight it is given in the final prediction, as it is considered to be more relevant to the prediction.\\r\\n\\r\\nOverall, weighted KNN can be a useful variation of the KNN algorithm when the distance between neighbors is an important factor in the prediction."},{"id":"parametric","metadata":{"permalink":"/CyberSec-NGIT/blog/parametric","editUrl":"https://github.com/stealthspectre/CyberSec-NGIT/blog/parametric.md","source":"@site/blog/parametric.md","title":"What is a Parametric Algorithm?","description":"In machine learning, a parametric algorithm is a type of algorithm that makes assumptions about the underlying distribution of the data. These assumptions are typically based on a specific mathematical model, such as a linear regression model or a Gaussian distribution.","date":"2023-03-29T10:09:46.255Z","formattedDate":"March 29, 2023","tags":[{"label":"regression","permalink":"/CyberSec-NGIT/blog/tags/regression"},{"label":"naive bayes","permalink":"/CyberSec-NGIT/blog/tags/naive-bayes"},{"label":"lda","permalink":"/CyberSec-NGIT/blog/tags/lda"},{"label":"guassian","permalink":"/CyberSec-NGIT/blog/tags/guassian"},{"label":"ml","permalink":"/CyberSec-NGIT/blog/tags/ml"},{"label":"algo","permalink":"/CyberSec-NGIT/blog/tags/algo"}],"readingTime":1.36,"hasTruncateMarker":false,"authors":[{"name":"Aneesh Sambu","title":"stealthspectre","url":"https://github.com/stealthspectre","imageURL":"https://github.com/stealthspectre.png","key":"aneesh"}],"frontMatter":{"slug":"parametric","title":"What is a Parametric Algorithm?","authors":"aneesh","tags":["regression","naive bayes","lda","guassian","ml","algo"]},"prevItem":{"title":"Diving into KNN","permalink":"/CyberSec-NGIT/blog/knn"},"nextItem":{"title":"What is a Non Parametric Algorithm?","permalink":"/CyberSec-NGIT/blog/non-parametric"}},"content":"In machine learning, a parametric algorithm is a type of algorithm that makes assumptions about the underlying distribution of the data. These assumptions are typically based on a specific mathematical model, such as a linear regression model or a Gaussian distribution.\\r\\n\\r\\nParametric algorithms estimate the parameters of the model based on the training data, and then use these parameters to make predictions or decisions on new data. Because they make assumptions about the underlying distribution, parametric algorithms can be more efficient and require less data than non-parametric algorithms.\\r\\n\\r\\nExamples of parametric algorithms include Linear [Regression](/blog/regression), Logistic Regression, Naive Bayes, and Linear Discriminant Analysis (LDA). These algorithms are often used in classification and regression tasks, and can be effective in a wide range of applications. However, they may not be as flexible as non-parametric algorithms and may not perform well if the underlying assumptions are not met.\\r\\n\\r\\nIn parametric algorithms, we are assuming that the data follows a specific mathematical model or distribution. For example, in linear regression, we assume that the relationship between the input variables and the output variable is linear. In logistic regression, we assume that the output variable follows a logistic distribution. In Naive Bayes, we assume that the input variables are conditionally independent given the output variable. In Linear Discriminant Analysis (LDA), we assume that the input variables follow a multivariate normal distribution. These assumptions allow us to estimate the parameters of the model based on the training data, and then use these parameters to make predictions or decisions on new data. However, if the underlying assumptions are not met, the performance of the algorithm may be affected."},{"id":"non-parametric","metadata":{"permalink":"/CyberSec-NGIT/blog/non-parametric","editUrl":"https://github.com/stealthspectre/CyberSec-NGIT/blog/non-parametric.md","source":"@site/blog/non-parametric.md","title":"What is a Non Parametric Algorithm?","description":"In machine learning, a non-parametric algorithm is a type of algorithm that does not make any assumptions about the underlying distribution of the data. This is in contrast to parametric algorithms, which assume that the data follows a specific distribution, such as a normal distribution.","date":"2023-03-29T10:07:06.671Z","formattedDate":"March 29, 2023","tags":[{"label":"random forest","permalink":"/CyberSec-NGIT/blog/tags/random-forest"},{"label":"decision trees","permalink":"/CyberSec-NGIT/blog/tags/decision-trees"},{"label":"knn","permalink":"/CyberSec-NGIT/blog/tags/knn"},{"label":"svm","permalink":"/CyberSec-NGIT/blog/tags/svm"},{"label":"ml","permalink":"/CyberSec-NGIT/blog/tags/ml"},{"label":"algo","permalink":"/CyberSec-NGIT/blog/tags/algo"}],"readingTime":0.78,"hasTruncateMarker":false,"authors":[{"name":"Aneesh Sambu","title":"stealthspectre","url":"https://github.com/stealthspectre","imageURL":"https://github.com/stealthspectre.png","key":"aneesh"}],"frontMatter":{"slug":"non-parametric","title":"What is a Non Parametric Algorithm?","authors":"aneesh","tags":["random forest","decision trees","knn","svm","ml","algo"]},"prevItem":{"title":"What is a Parametric Algorithm?","permalink":"/CyberSec-NGIT/blog/parametric"},"nextItem":{"title":"Decision Tree Classifier","permalink":"/CyberSec-NGIT/blog/decision-tree"}},"content":"In machine learning, a non-parametric algorithm is a type of algorithm that does not make any assumptions about the underlying distribution of the data. This is in contrast to parametric algorithms, which assume that the data follows a specific distribution, such as a normal distribution.\\r\\n\\r\\nNon-parametric algorithms are often used when the underlying distribution of the data is unknown or cannot be easily modeled. Instead of making assumptions about the distribution, non-parametric algorithms rely on the data itself to make predictions or decisions. This makes them more flexible and adaptable to a wide range of data types and distributions.\\r\\n\\r\\nExamples of non-parametric algorithms include [K-Nearest Neighbors](/blog/knn) (KNN), [Decision Trees](/blog/decision-tree), Random Forests, and Support Vector Machines (SVMs). These algorithms are often used in classification and [regression tasks](/blog/regression), and can be effective in a wide range of applications. However, they can also be computationally expensive and may require more data to achieve good performance compared to [parametric algorithms](/blog/parametric)."},{"id":"decision-tree","metadata":{"permalink":"/CyberSec-NGIT/blog/decision-tree","editUrl":"https://github.com/stealthspectre/CyberSec-NGIT/blog/decision-tree.md","source":"@site/blog/decision-tree.md","title":"Decision Tree Classifier","description":"- It is a type of Greedy Algorithm","date":"2023-03-27T18:58:24.486Z","formattedDate":"March 27, 2023","tags":[{"label":"ml","permalink":"/CyberSec-NGIT/blog/tags/ml"},{"label":"classifier","permalink":"/CyberSec-NGIT/blog/tags/classifier"},{"label":"algo","permalink":"/CyberSec-NGIT/blog/tags/algo"},{"label":"decision-tree","permalink":"/CyberSec-NGIT/blog/tags/decision-tree"}],"readingTime":1.35,"hasTruncateMarker":false,"authors":[{"name":"Aneesh Sambu","title":"stealthspectre","url":"https://github.com/stealthspectre","imageURL":"https://github.com/stealthspectre.png","key":"aneesh"}],"frontMatter":{"slug":"decision-tree","title":"Decision Tree Classifier","authors":"aneesh","tags":["ml","classifier","algo","decision-tree"]},"prevItem":{"title":"What is a Non Parametric Algorithm?","permalink":"/CyberSec-NGIT/blog/non-parametric"},"nextItem":{"title":"ARP Scan","permalink":"/CyberSec-NGIT/blog/arp-scan"}},"content":"- It is a type of **Greedy Algorithm**\\r\\n- In this we try to prepare a model by taking a set of features and try to prepare a binary tree where at the end of leaf notes we get a part of one feature only\\r\\n- So basically we are classifying the given features with their conditions and dividing them by borders and seperating them\\r\\n- example let the set of data be this\\r\\n  - let our sample feature set be ![](https://i.imgur.com/X2jL7pJ.png)\\r\\n  - where red is one type of feature and green is other\\r\\n  - where x axis denotes $X_0$ and y axis denotes $X_1$\\r\\n- the nodes other than **Leaf Nodes** are called **Decision Nodes**, we can find the required optimal decision for each node using information theory\\r\\n- ![](https://i.imgur.com/MCqpXVY.png)\\r\\n  - this is our decision tree, and leaf nodes consists of the classification\\r\\n- even if we want to add a new entity, we follow the decision nodes starting from top and like binary search tree if go through the tree and place it in its respective position\\r\\n- this is known as a greedy algorithm as we are finding the best case for our immediate sub task only, not considering future states prehandedly\\r\\n- using **Information Theory**, entropy and all we get optimal decision conditions (cause there can be many we should choose optimal condition) (it comes under **Information Gain**)\\r\\n- note: we use object oriented programming for implementing ml algorithms for ease of use and to use it more effectively\\r\\n- we use other quantifier for decision nodes along with **Entropy** which is known as **Gini Index**"},{"id":"arp-scan","metadata":{"permalink":"/CyberSec-NGIT/blog/arp-scan","editUrl":"https://github.com/stealthspectre/CyberSec-NGIT/blog/arp-scan.md","source":"@site/blog/arp-scan.md","title":"ARP Scan","description":"ARP","date":"2023-03-27T18:56:21.621Z","formattedDate":"March 27, 2023","tags":[{"label":"arp","permalink":"/CyberSec-NGIT/blog/tags/arp"},{"label":"arp-poisoning","permalink":"/CyberSec-NGIT/blog/tags/arp-poisoning"},{"label":"man-in-the-middle","permalink":"/CyberSec-NGIT/blog/tags/man-in-the-middle"}],"readingTime":2.22,"hasTruncateMarker":false,"authors":[{"name":"Aneesh Sambu","title":"stealthspectre","url":"https://github.com/stealthspectre","imageURL":"https://github.com/stealthspectre.png","key":"aneesh"}],"frontMatter":{"slug":"arp-scan","title":"ARP Scan","authors":"aneesh","tags":["arp","arp-poisoning","man-in-the-middle"]},"prevItem":{"title":"Decision Tree Classifier","permalink":"/CyberSec-NGIT/blog/decision-tree"}},"content":"## ARP\\n\\n- Address Resolution Protocol\\n  - Basic ARP identifies MAC addresses and maps them to the IP addresses\\n  - the thing where it stores MAC address is known as ARP cache\\n- arp-scan is a command-line tool that uses the ARP protocol to discover and fingerprint IP hosts on the local network\\n- arp-cache consists of associations our computer has learned about MAC addresses and IP addresses on the network\\n  - initially we may get the one to the default gateway only\\n- `arp -a` we get all the entries in the arp cache\\n  - ex: ![](https://i.imgur.com/amp52LY.png)\\n  - static type means it has been feeded statically whereas dynamic type means, it had to learn about it\\n  - physical address is the mapped MAC addresses\\n- we can delete a specific entry by `arp -d <entry ip>`\\n- but what if we want to send arp requests to an external web server\\n  - we send it through the default gateway, that is in our case is the router\\n  - then router sends its mac address to the requester and then the requester sends the external web IP address to router and the router handles the rest\\n- `sudo arp-scan -l` we get all the information about hosts in the network (but with arp cache, we may not still learn all the new info about computer)\\n- but `-l` is very noisy and can be easily detectable\\n- tools like netdiscover are used for stealthy scans\\n- [[ARP Poisoning]] is a type of MITM where hacker utilizes these ARP requests to steal info\\n\\n## ARP Poisoning\\n\\n- let this be our initial system ![](https://i.imgur.com/koBbVfx.png)\\n- then B turned out to be a hacker ![](https://i.imgur.com/kaPi0rs.png)\\n- observe A\'s intial ARP cache for default gateway which points to the router\\n- now the hacker sends specific ARP requests to A where he changes the default gateway of A to his address, so now if A wants to communicate with the router, it sends requests to its IP in which it follows the MAC address from ARP Cache, but our hacker B has changed that IP address mapping of router in the ARP cache to his address, so all the requests will be redirected to him and first he grabs the information and then sends to the router\\n- This is called Man In The Middle Attack ![](https://i.imgur.com/V6G5qfr.png)\\n- We again do in such a way where we want the router to send result back to us instead of A first\\n- In Kali we use Ettercap to perform this attack\\n- [Procedure video](https://www.youtube.com/watch?v=A7nih6SANYs) From 3:38\\n- Using [[DNS Cache Poisoning]] you can make this attack more better"}]}')}}]);