"use strict";(self.webpackChunkdocumentation=self.webpackChunkdocumentation||[]).push([[4854],{3905:(e,t,n)=>{n.d(t,{Zo:()=>d,kt:()=>_});var a=n(7294);function s(e,t,n){return t in e?Object.defineProperty(e,t,{value:n,enumerable:!0,configurable:!0,writable:!0}):e[t]=n,e}function r(e,t){var n=Object.keys(e);if(Object.getOwnPropertySymbols){var a=Object.getOwnPropertySymbols(e);t&&(a=a.filter((function(t){return Object.getOwnPropertyDescriptor(e,t).enumerable}))),n.push.apply(n,a)}return n}function c(e){for(var t=1;t<arguments.length;t++){var n=null!=arguments[t]?arguments[t]:{};t%2?r(Object(n),!0).forEach((function(t){s(e,t,n[t])})):Object.getOwnPropertyDescriptors?Object.defineProperties(e,Object.getOwnPropertyDescriptors(n)):r(Object(n)).forEach((function(t){Object.defineProperty(e,t,Object.getOwnPropertyDescriptor(n,t))}))}return e}function i(e,t){if(null==e)return{};var n,a,s=function(e,t){if(null==e)return{};var n,a,s={},r=Object.keys(e);for(a=0;a<r.length;a++)n=r[a],t.indexOf(n)>=0||(s[n]=e[n]);return s}(e,t);if(Object.getOwnPropertySymbols){var r=Object.getOwnPropertySymbols(e);for(a=0;a<r.length;a++)n=r[a],t.indexOf(n)>=0||Object.prototype.propertyIsEnumerable.call(e,n)&&(s[n]=e[n])}return s}var o=a.createContext({}),l=function(e){var t=a.useContext(o),n=t;return e&&(n="function"==typeof e?e(t):c(c({},t),e)),n},d=function(e){var t=l(e.components);return a.createElement(o.Provider,{value:t},e.children)},f="mdxType",u={inlineCode:"code",wrapper:function(e){var t=e.children;return a.createElement(a.Fragment,{},t)}},m=a.forwardRef((function(e,t){var n=e.components,s=e.mdxType,r=e.originalType,o=e.parentName,d=i(e,["components","mdxType","originalType","parentName"]),f=l(n),m=s,_=f["".concat(o,".").concat(m)]||f[m]||u[m]||r;return n?a.createElement(_,c(c({ref:t},d),{},{components:n})):a.createElement(_,c({ref:t},d))}));function _(e,t){var n=arguments,s=t&&t.mdxType;if("string"==typeof e||s){var r=n.length,c=new Array(r);c[0]=m;var i={};for(var o in t)hasOwnProperty.call(t,o)&&(i[o]=t[o]);i.originalType=e,i[f]="string"==typeof e?e:s,c[1]=i;for(var l=2;l<r;l++)c[l]=n[l];return a.createElement.apply(null,c)}return a.createElement.apply(null,n)}m.displayName="MDXCreateElement"},1719:(e,t,n)=>{n.r(t),n.d(t,{assets:()=>o,contentTitle:()=>c,default:()=>u,frontMatter:()=>r,metadata:()=>i,toc:()=>l});var a=n(7462),s=(n(7294),n(3905));const r={sidebar_position:4},c="General Idea of writing code for Classification",i={unversionedId:"ML-Based Zero Day Detection/general-code",id:"ML-Based Zero Day Detection/general-code",title:"General Idea of writing code for Classification",description:"## Import the Necessary Libraries",source:"@site/docs/ML-Based Zero Day Detection/general-code.md",sourceDirName:"ML-Based Zero Day Detection",slug:"/ML-Based Zero Day Detection/general-code",permalink:"/CyberSec-NGIT/docs/ML-Based Zero Day Detection/general-code",draft:!1,editUrl:"https://github.com/stealthspectre/CyberSec-NGIT/docs/ML-Based Zero Day Detection/general-code.md",tags:[],version:"current",sidebarPosition:4,frontMatter:{sidebar_position:4},sidebar:"tutorialSidebar",previous:{title:"The 22 Worthy Features",permalink:"/CyberSec-NGIT/docs/ML-Based Zero Day Detection/features"}},o={},l=[{value:"Accuracy for Decision Tree",id:"accuracy-for-decision-tree",level:3},{value:"Accuracy for Random Forest",id:"accuracy-for-random-forest",level:3},{value:"Accuracy for KNN",id:"accuracy-for-knn",level:3},{value:"Accuracy for Weighted KNN",id:"accuracy-for-weighted-knn",level:3},{value:"Accuracy for Gaussian Naive Bayes",id:"accuracy-for-gaussian-naive-bayes",level:3},{value:"Accuracy for MLP",id:"accuracy-for-mlp",level:3},{value:"Accuracy for QDA",id:"accuracy-for-qda",level:3},{value:"Get the Notebook from here",id:"get-the-notebook-from-here",level:3}],d={toc:l},f="wrapper";function u(e){let{components:t,...n}=e;return(0,s.kt)(f,(0,a.Z)({},d,n,{components:t,mdxType:"MDXLayout"}),(0,s.kt)("h1",{id:"general-idea-of-writing-code-for-classification"},"General Idea of writing code for Classification"),(0,s.kt)("blockquote",null,(0,s.kt)("h2",{parentName:"blockquote",id:"import-the-necessary-libraries"},"Import the Necessary Libraries")),(0,s.kt)("pre",null,(0,s.kt)("code",{parentName:"pre",className:"language-python"},"import pandas as pd\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.neural_network import MLPClassifier\nfrom sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n")),(0,s.kt)("hr",null),(0,s.kt)("blockquote",null,(0,s.kt)("h2",{parentName:"blockquote",id:"load-the-data-into-a-dataframe"},"Load the Data into a dataframe")),(0,s.kt)("pre",null,(0,s.kt)("code",{parentName:"pre",className:"language-python"},'# Load the data from CSV file\n# df = pd.read_csv(r"D:\\Stuff\\CyberSec\\archive\\03-02-2018.csv")\ndf = pd.read_csv(r"..\\Datasets\\IDS2018\\02-14-2018.csv")\n\n# Remove any rows with missing values\n# df = df.dropna()\n\n# Drop columns where all values are 0\n# df = df.loc[:, (df != 0).any(axis=0)]\n\n# to select first n rows only\n# df = df.iloc[:n,:]\n')),(0,s.kt)("hr",null),(0,s.kt)("blockquote",null,(0,s.kt)("h2",{parentName:"blockquote",id:"to-print-the-features-available-in-our-model"},"To print the features available in our model")),(0,s.kt)("pre",null,(0,s.kt)("code",{parentName:"pre",className:"language-python"},'for i, col_name in enumerate(df.columns):\n    print(f"Feature {i+1}:\\t\\"{col_name}\\"")\n')),(0,s.kt)("hr",null),(0,s.kt)("h3",{id:"accuracy-for-decision-tree"},"Accuracy for ",(0,s.kt)("a",{parentName:"h3",href:"/docs/ML-Based%20Zero%20Day%20Detection/ml-algorithms#decision-tree"},"Decision Tree")),(0,s.kt)("pre",null,(0,s.kt)("code",{parentName:"pre",className:"language-python"},'# specify column indexes to select\nselected_cols_idx = [1,2,4,5,6,11,15,19,29,33,34,35,40,46,48,58,59,62,66]\n\nselected_cols_idx = [x - 1 for x in selected_cols_idx]\n\n# select columns by index using iloc\nX = df.iloc[:, selected_cols_idx].values\ny = df.iloc[:, -1].values\n\n# Split the data into training and testing sets\nX_train, X_test, y_train, y_test = train_test_split(\n    X, y, test_size=0.2, random_state=42)\n\n# Train the decision tree classifier\nclf = DecisionTreeClassifier()\nclf.fit(X_train, y_train)\n\n# Test the classifier\naccuracy = clf.score(X_test, y_test)\n\n# Get the names of the selected columns\nselected_cols = list(df.columns[selected_cols_idx])\n\nprint("Accuracy for the following features combined", selected_cols, "is:", accuracy)\n')),(0,s.kt)("hr",null),(0,s.kt)("h3",{id:"accuracy-for-random-forest"},"Accuracy for ",(0,s.kt)("a",{parentName:"h3",href:"/docs/ML-Based%20Zero%20Day%20Detection/ml-algorithms#random-forest"},"Random Forest")),(0,s.kt)("pre",null,(0,s.kt)("code",{parentName:"pre",className:"language-python"},'# specify column indexes to select\nselected_cols_idx = [1,2,4,5,6,11,15,19,29,33,34,35,40,46,48,58,59,62,66]\nselected_cols_idx = [x - 1 for x in selected_cols_idx]\n\n# select columns by index using iloc\nX = df.iloc[:, selected_cols_idx].values\ny = df.iloc[:, -1].values\n\n# Split the data into training and testing sets\nX_train, X_test, y_train, y_test = train_test_split(\n    X, y, test_size=0.2, random_state=42)\n\n# Train the Random Forest classifier\nrf = RandomForestClassifier(n_estimators=100, random_state=42)\nrf.fit(X_train, y_train)\n\n# Test the classifier\naccuracy = rf.score(X_test, y_test)\n\n# Get the names of the selected columns\nselected_cols = list(df.columns[selected_cols_idx])\n\nprint("Accuracy for the following features combined", selected_cols, "is:", accuracy)\n')),(0,s.kt)("hr",null),(0,s.kt)("h3",{id:"accuracy-for-knn"},"Accuracy for ",(0,s.kt)("a",{parentName:"h3",href:"/docs/ML-Based%20Zero%20Day%20Detection/ml-algorithms#knn"},"KNN")),(0,s.kt)("pre",null,(0,s.kt)("code",{parentName:"pre",className:"language-python"},'# specify column indexes to select\nselected_cols_idx = [1,2,4,5,6,11,15,19,29,33,34,35,40,46,48,58,59,62,66]\nselected_cols_idx = [x - 1 for x in selected_cols_idx]\n\n# select columns by index using iloc\nX = df.iloc[:, selected_cols_idx].values\ny = df.iloc[:, -1].values\n\n# Split the data into training and testing sets\nX_train, X_test, y_train, y_test = train_test_split(\n    X, y, test_size=0.2, random_state=42)\n\n# Train the KNN classifier\nknn = KNeighborsClassifier()\nknn.fit(X_train, y_train)\n\n# Test the classifier\naccuracy = knn.score(X_test, y_test)\n\n# Get the names of the selected columns\nselected_cols = list(df.columns[selected_cols_idx])\n\nprint("Accuracy for the following features combined", selected_cols, "is:", accuracy)\n')),(0,s.kt)("hr",null),(0,s.kt)("h3",{id:"accuracy-for-weighted-knn"},"Accuracy for ",(0,s.kt)("a",{parentName:"h3",href:"/docs/ML-Based%20Zero%20Day%20Detection/ml-algorithms#knn"},"Weighted KNN")),(0,s.kt)("pre",null,(0,s.kt)("code",{parentName:"pre",className:"language-python"},'# specify column indexes to select\nselected_cols_idx = [1,2,4,5,6,11,15,19,29,33,34,35,40,46,48,58,59,62,66]\nselected_cols_idx = [x - 1 for x in selected_cols_idx]\n\n# select columns by index using iloc\nX = df.iloc[:, selected_cols_idx].values\ny = df.iloc[:, -1].values\n\n# Split the data into training and testing sets\nX_train, X_test, y_train, y_test = train_test_split(\n    X, y, test_size=0.2, random_state=42)\n\n# Train the weighted KNN classifier\nknn = KNeighborsClassifier(weights=\'distance\')\nknn.fit(X_train, y_train)\n\n# Test the classifier\naccuracy = knn.score(X_test, y_test)\n\n# Get the names of the selected columns\nselected_cols = list(df.columns[selected_cols_idx])\n\nprint("Accuracy for the following features combined", selected_cols, "is:", accuracy)\n')),(0,s.kt)("hr",null),(0,s.kt)("h3",{id:"accuracy-for-gaussian-naive-bayes"},"Accuracy for ",(0,s.kt)("a",{parentName:"h3",href:"/docs/ML-Based%20Zero%20Day%20Detection/ml-algorithms#na%C3%AFve-bayes"},"Gaussian Naive Bayes")),(0,s.kt)("pre",null,(0,s.kt)("code",{parentName:"pre",className:"language-python"},'# Specify column indexes to select\nselected_cols_idx = [1,2,4,5,6,11,15,19,29,33,34,35,40,46,48,58,59,62,66]\nselected_cols_idx = [x - 1 for x in selected_cols_idx]\n\n# Select columns by index using iloc\nX = df.iloc[:, selected_cols_idx].values\ny = df.iloc[:, -1].values\n\n# Split the data into training and testing sets\nX_train, X_test, y_train, y_test = train_test_split(\n    X, y, test_size=0.2, random_state=42)\n\n# Train the Gaussian Naive Bayes classifier\ngnb = GaussianNB()\ngnb.fit(X_train, y_train)\n\n# Test the classifier\naccuracy = gnb.score(X_test, y_test)\n\n# Get the names of the selected columns\nselected_cols = list(df.columns[selected_cols_idx])\n\nprint("Accuracy for the following features combined", selected_cols, "is:", accuracy)\n')),(0,s.kt)("hr",null),(0,s.kt)("h3",{id:"accuracy-for-mlp"},"Accuracy for ",(0,s.kt)("a",{parentName:"h3",href:"/docs/ML-Based%20Zero%20Day%20Detection/ml-algorithms#mlp"},"MLP")),(0,s.kt)("pre",null,(0,s.kt)("code",{parentName:"pre",className:"language-python"},'# specify column indexes to select\nselected_cols_idx = [1, 2, 4, 5, 6, 11, 15, 19, 29, 33, 34, 35, 40, 46, 48, 58, 59, 62, 66]\nselected_cols_idx = [x - 1 for x in selected_cols_idx]\n\n# select columns by index using iloc\nX = df.iloc[:, selected_cols_idx].values\ny = df.iloc[:, -1].values\n\n# split the data into training and testing sets\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n\n# instantiate the MLP classifier\nmlp = MLPClassifier(hidden_layer_sizes=(100, 50), max_iter=300, alpha=0.0001,\n                    solver=\'adam\', random_state=42, tol=0.0001)\n\n# train the MLP classifier\nmlp.fit(X_train, y_train)\n\n# test the MLP classifier\naccuracy = mlp.score(X_test, y_test)\n\n# get the names of the selected columns\nselected_cols = list(df.columns[selected_cols_idx])\n\nprint("Accuracy for the following features combined", selected_cols, "is:", accuracy)\n')),(0,s.kt)("hr",null),(0,s.kt)("h3",{id:"accuracy-for-qda"},"Accuracy for ",(0,s.kt)("a",{parentName:"h3",href:"/docs/ML-Based%20Zero%20Day%20Detection/ml-algorithms#qda"},"QDA")),(0,s.kt)("pre",null,(0,s.kt)("code",{parentName:"pre",className:"language-python"},'from sklearn.preprocessing import StandardScaler\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n\n# specify column indexes to select\nselected_cols_idx = [1, 2, 4, 5, 6, 11, 15, 19, 29, 33, 34, 35, 40, 46, 48, 58, 59, 62, 66]\nselected_cols_idx = [x - 1 for x in selected_cols_idx]\n\n# select columns by index using iloc\nX = df.iloc[:, selected_cols_idx].values\ny = df.iloc[:, -1].values\n\n# split the data into training and testing sets\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n\n# scale the data\nscaler = StandardScaler()\nX_train = scaler.fit_transform(X_train)\nX_test = scaler.transform(X_test)\n\n# instantiate the QDA classifier\nqda = QuadraticDiscriminantAnalysis(reg_param=0.1)\n\n# train the QDA classifier\nqda.fit(X_train, y_train)\n\n# test the QDA classifier\naccuracy = qda.score(X_test, y_test)\n\n# get the names of the selected columns\nselected_cols = list(df.columns[selected_cols_idx])\n\nprint("Accuracy for the following features combined", selected_cols, "is:", accuracy)\n')),(0,s.kt)("hr",null),(0,s.kt)("h3",{id:"get-the-notebook-from-here"},"Get the Notebook from here"),(0,s.kt)("p",null,(0,s.kt)("a",{parentName:"p",href:"https://github.com/stealthspectre/CyberSec-NGIT/blob/main/Notebooks/ml_imp_features.ipynb"},"CyberSec-NGIT/ml_imp_features.ipynb at main \xb7 stealthspectre/CyberSec-NGIT (github.com)")))}u.isMDXComponent=!0}}]);