{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the dataset\n",
    "df = pd.read_csv(r\"D:\\Stuff\\CyberSec\\Datasets\\IDS2018\\02-14-2018.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Split the dataset into training and validation sets\n",
    "train_df, val_df = train_test_split(df, test_size=0.2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Exception encountered when calling layer \"resnet50\" (type Functional).\n\nInput 0 of layer \"conv1_conv\" is incompatible with the layer: expected axis -1 of input shape to have value 3, but received input with shape (None, 13, 13, 2048)\n\nCall arguments received by layer \"resnet50\" (type Functional):\n  • inputs=tf.Tensor(shape=(None, 7, 7, 2048), dtype=float32)\n  • training=False\n  • mask=None",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 46\u001b[0m\n\u001b[0;32m     43\u001b[0m x \u001b[39m=\u001b[39m layers\u001b[39m.\u001b[39mReshape(base_output_shape)(x)\n\u001b[0;32m     45\u001b[0m \u001b[39m# Apply the base model to the reshaped output of the last Dense layer\u001b[39;00m\n\u001b[1;32m---> 46\u001b[0m x \u001b[39m=\u001b[39m base_model(x, training\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m)\n\u001b[0;32m     48\u001b[0m \u001b[39m# Add a few more layers on top of the base model\u001b[39;00m\n\u001b[0;32m     49\u001b[0m x \u001b[39m=\u001b[39m layers\u001b[39m.\u001b[39mGlobalAveragePooling2D()(x)\n",
      "File \u001b[1;32mc:\\Users\\Aneesh\\.conda\\envs\\cyber\\lib\\site-packages\\keras\\utils\\traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n\u001b[0;32m     68\u001b[0m     \u001b[39m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m     69\u001b[0m     \u001b[39m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m---> 70\u001b[0m     \u001b[39mraise\u001b[39;00m e\u001b[39m.\u001b[39mwith_traceback(filtered_tb) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39m\n\u001b[0;32m     71\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[0;32m     72\u001b[0m     \u001b[39mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32mc:\\Users\\Aneesh\\.conda\\envs\\cyber\\lib\\site-packages\\keras\\engine\\input_spec.py:280\u001b[0m, in \u001b[0;36massert_input_compatibility\u001b[1;34m(input_spec, inputs, layer_name)\u001b[0m\n\u001b[0;32m    275\u001b[0m             value \u001b[39m=\u001b[39m value\u001b[39m.\u001b[39mvalue\n\u001b[0;32m    276\u001b[0m         \u001b[39mif\u001b[39;00m value \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m shape_as_list[\u001b[39mint\u001b[39m(axis)] \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m {\n\u001b[0;32m    277\u001b[0m             value,\n\u001b[0;32m    278\u001b[0m             \u001b[39mNone\u001b[39;00m,\n\u001b[0;32m    279\u001b[0m         }:\n\u001b[1;32m--> 280\u001b[0m             \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m    281\u001b[0m                 \u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mInput \u001b[39m\u001b[39m{\u001b[39;00minput_index\u001b[39m}\u001b[39;00m\u001b[39m of layer \u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00mlayer_name\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m is \u001b[39m\u001b[39m'\u001b[39m\n\u001b[0;32m    282\u001b[0m                 \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mincompatible with the layer: expected axis \u001b[39m\u001b[39m{\u001b[39;00maxis\u001b[39m}\u001b[39;00m\u001b[39m \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    283\u001b[0m                 \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mof input shape to have value \u001b[39m\u001b[39m{\u001b[39;00mvalue\u001b[39m}\u001b[39;00m\u001b[39m, \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    284\u001b[0m                 \u001b[39m\"\u001b[39m\u001b[39mbut received input with \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    285\u001b[0m                 \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mshape \u001b[39m\u001b[39m{\u001b[39;00mdisplay_shape(x\u001b[39m.\u001b[39mshape)\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[0;32m    286\u001b[0m             )\n\u001b[0;32m    287\u001b[0m \u001b[39m# Check shape.\u001b[39;00m\n\u001b[0;32m    288\u001b[0m \u001b[39mif\u001b[39;00m spec\u001b[39m.\u001b[39mshape \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m shape\u001b[39m.\u001b[39mrank \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "\u001b[1;31mValueError\u001b[0m: Exception encountered when calling layer \"resnet50\" (type Functional).\n\nInput 0 of layer \"conv1_conv\" is incompatible with the layer: expected axis -1 of input shape to have value 3, but received input with shape (None, 13, 13, 2048)\n\nCall arguments received by layer \"resnet50\" (type Functional):\n  • inputs=tf.Tensor(shape=(None, 7, 7, 2048), dtype=float32)\n  • training=False\n  • mask=None"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Load the dataset into a pandas dataframe\n",
    "data = pd.read_csv(r\"D:\\Stuff\\CyberSec\\Datasets\\IDS2018\\02-14-2018.csv\")\n",
    "\n",
    "# Split the dataset into training and testing sets\n",
    "train_data, test_data = train_test_split(data, test_size=0.2)\n",
    "\n",
    "# Define the input shape of the model\n",
    "input_shape = (train_data.shape[1]-1,)\n",
    "\n",
    "# Define the base model\n",
    "base_model = tf.keras.applications.ResNet50(\n",
    "    include_top=False,\n",
    "    weights='imagenet',\n",
    "    input_shape=(224,224,3)\n",
    ")\n",
    "\n",
    "# Freeze the weights of the base model\n",
    "base_model.trainable = False\n",
    "\n",
    "# Create the final model by adding a few layers on top of the base model\n",
    "inputs = keras.Input(shape=input_shape)\n",
    "x = layers.Dense(128, activation='relu')(inputs)\n",
    "x = layers.BatchNormalization()(x)\n",
    "x = layers.Dropout(0.5)(x)\n",
    "x = layers.Dense(64, activation='relu')(x)\n",
    "x = layers.BatchNormalization()(x)\n",
    "x = layers.Dropout(0.5)(x)\n",
    "\n",
    "# Flatten the output of the last Dense layer\n",
    "x = layers.Flatten()(x)\n",
    "\n",
    "# Compute the shape of the output of the ResNet50 base model\n",
    "base_output_shape = base_model.layers[-1].output_shape[1:]\n",
    "\n",
    "# Reshape the output of the last Dense layer to match the input shape of the base model\n",
    "x = layers.Dense(tf.reduce_prod(base_output_shape))(x)\n",
    "x = layers.Reshape(base_output_shape)(x)\n",
    "\n",
    "# Apply the base model to the reshaped output of the last Dense layer\n",
    "x = base_model(x, training=False)\n",
    "\n",
    "# Add a few more layers on top of the base model\n",
    "x = layers.GlobalAveragePooling2D()(x)\n",
    "x = layers.Dense(64, activation='relu')(x)\n",
    "x = layers.BatchNormalization()(x)\n",
    "x = layers.Dropout(0.5)(x)\n",
    "\n",
    "# Add the final output layer\n",
    "outputs = layers.Dense(1, activation='sigmoid')(x)\n",
    "\n",
    "# Create the final model\n",
    "model = keras.Model(inputs, outputs)\n",
    "\n",
    "# Compile the model\n",
    "model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(learning_rate=1e-3),\n",
    "    loss=tf.keras.losses.BinaryCrossentropy(from_logits=False),\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(\n",
    "    train_data.iloc[:,:-1], train_data.iloc[:,-1],\n",
    "    validation_split=0.2,\n",
    "    epochs=10,\n",
    "    batch_size=64\n",
    ")\n",
    "\n",
    "# Save the pretrained model\n",
    "model.save('model')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cyber",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
